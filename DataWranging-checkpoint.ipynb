{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init(r\"C:\\apache-spark\\spark-2.4.3-bin-hadoop2.7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Weblog').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\richa\\\\Desktop\\\\PythonPractice\\\\BigData\\\\PySpark\\\\WeblogAnalysis\\\\NASA_access_log_Aug95.gz',\n",
       " 'C:\\\\Users\\\\richa\\\\Desktop\\\\PythonPractice\\\\BigData\\\\PySpark\\\\WeblogAnalysis\\\\NASA_access_log_Jul95.gz']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "raw_data_files = glob.glob(r'C:\\Users\\richa\\Desktop\\PythonPractice\\BigData\\PySpark\\WeblogAnalysis\\*.gz')\n",
    "raw_data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_df = spark.read.text(raw_data_files)\n",
    "base_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(base_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------+\n",
      "|value                                                                                                                  |\n",
      "+-----------------------------------------------------------------------------------------------------------------------+\n",
      "|199.72.81.55 - - [01/Jul/1995:00:00:01 -0400] \"GET /history/apollo/ HTTP/1.0\" 200 6245                                 |\n",
      "|unicomp6.unicomp.net - - [01/Jul/1995:00:00:06 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985                      |\n",
      "|199.120.110.21 - - [01/Jul/1995:00:00:09 -0400] \"GET /shuttle/missions/sts-73/mission-sts-73.html HTTP/1.0\" 200 4085   |\n",
      "|burger.letters.com - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/countdown/liftoff.html HTTP/1.0\" 304 0               |\n",
      "|199.120.110.21 - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/missions/sts-73/sts-73-patch-small.gif HTTP/1.0\" 200 4179|\n",
      "|burger.letters.com - - [01/Jul/1995:00:00:12 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 304 0                    |\n",
      "|burger.letters.com - - [01/Jul/1995:00:00:12 -0400] \"GET /shuttle/countdown/video/livevideo.gif HTTP/1.0\" 200 0        |\n",
      "|205.212.115.106 - - [01/Jul/1995:00:00:12 -0400] \"GET /shuttle/countdown/countdown.html HTTP/1.0\" 200 3985             |\n",
      "|d104.aa.net - - [01/Jul/1995:00:00:13 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985                               |\n",
      "|129.94.144.152 - - [01/Jul/1995:00:00:13 -0400] \"GET / HTTP/1.0\" 200 7074                                              |\n",
      "+-----------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3461613"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_logs=[item['value'] for item in base_df.take(15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['199.72.81.55 - - [01/Jul/1995:00:00:01 -0400] \"GET /history/apollo/ HTTP/1.0\" 200 6245',\n",
       " 'unicomp6.unicomp.net - - [01/Jul/1995:00:00:06 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985',\n",
       " '199.120.110.21 - - [01/Jul/1995:00:00:09 -0400] \"GET /shuttle/missions/sts-73/mission-sts-73.html HTTP/1.0\" 200 4085',\n",
       " 'burger.letters.com - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/countdown/liftoff.html HTTP/1.0\" 304 0',\n",
       " '199.120.110.21 - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/missions/sts-73/sts-73-patch-small.gif HTTP/1.0\" 200 4179',\n",
       " 'burger.letters.com - - [01/Jul/1995:00:00:12 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 304 0',\n",
       " 'burger.letters.com - - [01/Jul/1995:00:00:12 -0400] \"GET /shuttle/countdown/video/livevideo.gif HTTP/1.0\" 200 0',\n",
       " '205.212.115.106 - - [01/Jul/1995:00:00:12 -0400] \"GET /shuttle/countdown/countdown.html HTTP/1.0\" 200 3985',\n",
       " 'd104.aa.net - - [01/Jul/1995:00:00:13 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985',\n",
       " '129.94.144.152 - - [01/Jul/1995:00:00:13 -0400] \"GET / HTTP/1.0\" 200 7074',\n",
       " 'unicomp6.unicomp.net - - [01/Jul/1995:00:00:14 -0400] \"GET /shuttle/countdown/count.gif HTTP/1.0\" 200 40310',\n",
       " 'unicomp6.unicomp.net - - [01/Jul/1995:00:00:14 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 200 786',\n",
       " 'unicomp6.unicomp.net - - [01/Jul/1995:00:00:14 -0400] \"GET /images/KSC-logosmall.gif HTTP/1.0\" 200 1204',\n",
       " 'd104.aa.net - - [01/Jul/1995:00:00:15 -0400] \"GET /shuttle/countdown/count.gif HTTP/1.0\" 200 40310',\n",
       " 'd104.aa.net - - [01/Jul/1995:00:00:15 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 200 786']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['199.72.81.55',\n",
       " 'unicomp6.unicomp.net',\n",
       " '199.120.110.21',\n",
       " 'burger.letters.com',\n",
       " '199.120.110.21',\n",
       " 'burger.letters.com',\n",
       " 'burger.letters.com',\n",
       " '205.212.115.106',\n",
       " 'd104.aa.net',\n",
       " '129.94.144.152',\n",
       " 'unicomp6.unicomp.net',\n",
       " 'unicomp6.unicomp.net',\n",
       " 'unicomp6.unicomp.net',\n",
       " 'd104.aa.net',\n",
       " 'd104.aa.net']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract the hostname from the logs\n",
    "\n",
    "host_pattern = r'(^\\S+\\.[\\S+\\.]+\\S+)\\s'\n",
    "hosts = [re.search(host_pattern, item).group(1)\n",
    "           if re.search(host_pattern, item)\n",
    "           else 'no match'\n",
    "           for item in sample_logs]\n",
    "hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01/Jul/1995:00:00:01 -0400',\n",
       " '01/Jul/1995:00:00:06 -0400',\n",
       " '01/Jul/1995:00:00:09 -0400',\n",
       " '01/Jul/1995:00:00:11 -0400',\n",
       " '01/Jul/1995:00:00:11 -0400',\n",
       " '01/Jul/1995:00:00:12 -0400',\n",
       " '01/Jul/1995:00:00:12 -0400',\n",
       " '01/Jul/1995:00:00:12 -0400',\n",
       " '01/Jul/1995:00:00:13 -0400',\n",
       " '01/Jul/1995:00:00:13 -0400',\n",
       " '01/Jul/1995:00:00:14 -0400',\n",
       " '01/Jul/1995:00:00:14 -0400',\n",
       " '01/Jul/1995:00:00:14 -0400',\n",
       " '01/Jul/1995:00:00:15 -0400',\n",
       " '01/Jul/1995:00:00:15 -0400']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting timestamps\n",
    "\n",
    "ts_pattern = r'\\s+\\[(\\d+.*?)\\]'\n",
    "timestamps = [re.search(ts_pattern, item).group(1) for item in sample_logs]\n",
    "timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('GET', '/history/apollo/', 'HTTP/1.0'),\n",
       " ('GET', '/shuttle/countdown/', 'HTTP/1.0'),\n",
       " ('GET', '/shuttle/missions/sts-73/mission-sts-73.html', 'HTTP/1.0'),\n",
       " ('GET', '/shuttle/countdown/liftoff.html', 'HTTP/1.0'),\n",
       " ('GET', '/shuttle/missions/sts-73/sts-73-patch-small.gif', 'HTTP/1.0'),\n",
       " ('GET', '/images/NASA-logosmall.gif', 'HTTP/1.0'),\n",
       " ('GET', '/shuttle/countdown/video/livevideo.gif', 'HTTP/1.0'),\n",
       " ('GET', '/shuttle/countdown/countdown.html', 'HTTP/1.0'),\n",
       " ('GET', '/shuttle/countdown/', 'HTTP/1.0'),\n",
       " ('GET', '/', 'HTTP/1.0'),\n",
       " ('GET', '/shuttle/countdown/count.gif', 'HTTP/1.0'),\n",
       " ('GET', '/images/NASA-logosmall.gif', 'HTTP/1.0'),\n",
       " ('GET', '/images/KSC-logosmall.gif', 'HTTP/1.0'),\n",
       " ('GET', '/shuttle/countdown/count.gif', 'HTTP/1.0'),\n",
       " ('GET', '/images/NASA-logosmall.gif', 'HTTP/1.0')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting HTTP request method, URIs, and protocol\n",
    "\n",
    "method_uri_protocol_pattern = r'\\\"(\\S+)\\s+(.*)\\s+(.*?)\\\"'\n",
    "method_uri_protocol = [re.search(method_uri_protocol_pattern, item).groups()\n",
    "               if re.search(method_uri_protocol_pattern, item)\n",
    "               else 'no match'\n",
    "              for item in sample_logs]\n",
    "method_uri_protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['200', '200', '200', '304', '200', '304', '200', '200', '200', '200', '200', '200', '200', '200', '200']\n"
     ]
    }
   ],
   "source": [
    "#Extracting HTTP status codes\n",
    "\n",
    "status_pattern = r'\\\"\\s+(\\d+)'\n",
    "status = [re.search(status_pattern, item).group(1) for item in sample_logs]\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6245', '3985', '4085', '0', '4179', '0', '0', '3985', '3985', '7074', '40310', '786', '1204', '40310', '786']\n"
     ]
    }
   ],
   "source": [
    "#Extracting HTTP response content size\n",
    "\n",
    "content_size_pattern = r'\\s(\\d+)$'\n",
    "content_size = [re.search(content_size_pattern, item).group(1) for item in sample_logs]\n",
    "print(content_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+--------------------+--------+------+------------+\n",
      "|                host|           timestamp|method|            endpoint|protocol|status|content_size|\n",
      "+--------------------+--------------------+------+--------------------+--------+------+------------+\n",
      "|        199.72.81.55|01/Jul/1995:00:00...|   GET|    /history/apollo/|HTTP/1.0|   200|        6245|\n",
      "|unicomp6.unicomp.net|01/Jul/1995:00:00...|   GET| /shuttle/countdown/|HTTP/1.0|   200|        3985|\n",
      "|      199.120.110.21|01/Jul/1995:00:00...|   GET|/shuttle/missions...|HTTP/1.0|   200|        4085|\n",
      "|  burger.letters.com|01/Jul/1995:00:00...|   GET|/shuttle/countdow...|HTTP/1.0|   304|           0|\n",
      "|      199.120.110.21|01/Jul/1995:00:00...|   GET|/shuttle/missions...|HTTP/1.0|   200|        4179|\n",
      "|  burger.letters.com|01/Jul/1995:00:00...|   GET|/images/NASA-logo...|HTTP/1.0|   304|           0|\n",
      "|  burger.letters.com|01/Jul/1995:00:00...|   GET|/shuttle/countdow...|HTTP/1.0|   200|           0|\n",
      "|     205.212.115.106|01/Jul/1995:00:00...|   GET|/shuttle/countdow...|HTTP/1.0|   200|        3985|\n",
      "|         d104.aa.net|01/Jul/1995:00:00...|   GET| /shuttle/countdown/|HTTP/1.0|   200|        3985|\n",
      "|      129.94.144.152|01/Jul/1995:00:00...|   GET|                   /|HTTP/1.0|   200|        7074|\n",
      "+--------------------+--------------------+------+--------------------+--------+------+------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "(3461613, 7)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract\n",
    "\n",
    "logs_df = base_df.select(regexp_extract('value', host_pattern, 1).alias('host'),\n",
    "                         regexp_extract('value', ts_pattern, 1).alias('timestamp'),\n",
    "                         regexp_extract('value', method_uri_protocol_pattern, 1).alias('method'),\n",
    "                         regexp_extract('value', method_uri_protocol_pattern, 2).alias('endpoint'),\n",
    "                         regexp_extract('value', method_uri_protocol_pattern, 3).alias('protocol'),\n",
    "                         regexp_extract('value', status_pattern, 1).cast('integer').alias('status'),\n",
    "                         regexp_extract('value', content_size_pattern, 1).cast('integer').alias('content_size'))\n",
    "logs_df.show(10, truncate=True)\n",
    "print((logs_df.count(), len(logs_df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df.filter(base_df['value'].isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33905"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_rows_df = logs_df.filter(logs_df['host'].isNull()|\n",
    "                             logs_df['timestamp'].isNull() |\n",
    "                             logs_df['method'].isNull() |\n",
    "                             logs_df['endpoint'].isNull() |\n",
    "                             logs_df['status'].isNull() |\n",
    "                             logs_df['content_size'].isNull()|\n",
    "                             logs_df['protocol'].isNull())\n",
    "bad_rows_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------+--------+--------+------+------------+\n",
      "|host|timestamp|method|endpoint|protocol|status|content_size|\n",
      "+----+---------+------+--------+--------+------+------------+\n",
      "|   0|        0|     0|       0|       0|     1|       33905|\n",
      "+----+---------+------+--------+--------+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import sum as spark_sum\n",
    "\n",
    "def count_null(col_name):\n",
    "    return spark_sum(col(col_name).isNull().cast('integer')).alias(col_name)\n",
    "\n",
    "# Build up a list of column expressions, one per column.\n",
    "exprs = [count_null(col_name) for col_name in logs_df.columns]\n",
    "\n",
    "# Run the aggregation. The *exprs converts the list of expressions into\n",
    "# variable function arguments.\n",
    "logs_df.agg(*exprs).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling nulls in HTTP status\n",
    "logs_df = logs_df[logs_df['status'].isNotNull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix the rows with null content_size\n",
    "logs_df = logs_df.na.fill({'content_size': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "\n",
    "month_map = {\n",
    "  'Jan': 1, 'Feb': 2, 'Mar':3, 'Apr':4, 'May':5, 'Jun':6, 'Jul':7,\n",
    "  'Aug':8,  'Sep': 9, 'Oct':10, 'Nov': 11, 'Dec': 12\n",
    "}\n",
    "\n",
    "def parse_clf_time(text):\n",
    "    \"\"\" Convert Common Log time format into a Python datetime object\n",
    "    Args:\n",
    "        text (str): date and time in Apache time format [dd/mmm/yyyy:hh:mm:ss (+/-)zzzz]\n",
    "    Returns:\n",
    "        a string suitable for passing to CAST('timestamp')\n",
    "    \"\"\"\n",
    "    # NOTE: We're ignoring the time zones here, might need to be handled depending on the problem you are solving\n",
    "    return \"{0:04d}-{1:02d}-{2:02d} {3:02d}:{4:02d}:{5:02d}\".format(\n",
    "      int(text[7:11]),\n",
    "      month_map[text[3:6]],\n",
    "      int(text[0:2]),\n",
    "      int(text[12:14]),\n",
    "      int(text[15:17]),\n",
    "      int(text[18:20])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+--------------------+--------+------+------------+-------------------+\n",
      "|                host|method|            endpoint|protocol|status|content_size|               time|\n",
      "+--------------------+------+--------------------+--------+------+------------+-------------------+\n",
      "|        199.72.81.55|   GET|    /history/apollo/|HTTP/1.0|   200|        6245|1995-07-01 00:00:01|\n",
      "|unicomp6.unicomp.net|   GET| /shuttle/countdown/|HTTP/1.0|   200|        3985|1995-07-01 00:00:06|\n",
      "|      199.120.110.21|   GET|/shuttle/missions...|HTTP/1.0|   200|        4085|1995-07-01 00:00:09|\n",
      "|  burger.letters.com|   GET|/shuttle/countdow...|HTTP/1.0|   304|           0|1995-07-01 00:00:11|\n",
      "|      199.120.110.21|   GET|/shuttle/missions...|HTTP/1.0|   200|        4179|1995-07-01 00:00:11|\n",
      "|  burger.letters.com|   GET|/images/NASA-logo...|HTTP/1.0|   304|           0|1995-07-01 00:00:12|\n",
      "|  burger.letters.com|   GET|/shuttle/countdow...|HTTP/1.0|   200|           0|1995-07-01 00:00:12|\n",
      "|     205.212.115.106|   GET|/shuttle/countdow...|HTTP/1.0|   200|        3985|1995-07-01 00:00:12|\n",
      "|         d104.aa.net|   GET| /shuttle/countdown/|HTTP/1.0|   200|        3985|1995-07-01 00:00:13|\n",
      "|      129.94.144.152|   GET|                   /|HTTP/1.0|   200|        7074|1995-07-01 00:00:13|\n",
      "+--------------------+------+--------------------+--------+------+------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "udf_parse_time = udf(parse_clf_time)\n",
    "\n",
    "logs_df = (logs_df.select('*', udf_parse_time(logs_df['timestamp']).cast('timestamp').alias('time')).drop('timestamp'))\n",
    "logs_df.show(10, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>content_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>3461612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>18928.844398216785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>73031.47260949228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>6823936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary        content_size\n",
       "0   count             3461612\n",
       "1    mean  18928.844398216785\n",
       "2  stddev   73031.47260949228\n",
       "3     min                   0\n",
       "4     max             6823936"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_size_summary_df = logs_df.describe(['content_size'])\n",
    "content_size_summary_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_content_size</th>\n",
       "      <th>max_content_size</th>\n",
       "      <th>mean_content_size</th>\n",
       "      <th>std_content_size</th>\n",
       "      <th>count_content_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6823936</td>\n",
       "      <td>18928.844398</td>\n",
       "      <td>73031.472609</td>\n",
       "      <td>3461612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   min_content_size  max_content_size  mean_content_size  std_content_size  \\\n",
       "0                 0           6823936       18928.844398      73031.472609   \n",
       "\n",
       "   count_content_size  \n",
       "0             3461612  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "(logs_df.agg(F.min(logs_df['content_size']).alias('min_content_size'),\n",
    "             F.max(logs_df['content_size']).alias('max_content_size'),\n",
    "             F.mean(logs_df['content_size']).alias('mean_content_size'),\n",
    "             F.stddev(logs_df['content_size']).alias('std_content_size'),\n",
    "             F.count(logs_df['content_size']).alias('count_content_size'))\n",
    "        .toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
